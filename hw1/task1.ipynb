{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Descriptive Statistics - CEO Compensation Analysis\n",
    "\n",
    "This notebook analyzes CEO compensation data from 1999, examining various statistical measures and relationships between variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('/mnt/user-data/uploads/ceo.xls')\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset information:\")\n",
    "df.info()\n",
    "print(\"\\nBasic statistics:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1(a) Location Measures for Total Compensation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totcomp = df['totcomp'].dropna()\n",
    "\n",
    "mean_val = totcomp.mean()\n",
    "trimmed_mean = stats.trim_mean(totcomp, 0.05)\n",
    "median_val = totcomp.median()\n",
    "q1 = totcomp.quantile(0.25)\n",
    "q3 = totcomp.quantile(0.75)\n",
    "q05 = totcomp.quantile(0.05)\n",
    "q95 = totcomp.quantile(0.95)\n",
    "\n",
    "print(\"LOCATION MEASURES FOR TOTAL COMPENSATION\\n\" + \"=\"*50)\n",
    "print(f\"Mean: ${mean_val:,.2f}\")\n",
    "print(f\"5%-Trimmed Mean: ${trimmed_mean:,.2f}\")\n",
    "print(f\"Median (Q2): ${median_val:,.2f}\")\n",
    "print(f\"Lower Quartile (Q1): ${q1:,.2f}\")\n",
    "print(f\"Upper Quartile (Q3): ${q3:,.2f}\")\n",
    "print(f\"Lower 5% Quantile: ${q05:,.2f}\")\n",
    "print(f\"Upper 95% Quantile: ${q95:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Economic Interpretation:\n",
    "\n",
    "**Mean**: The average CEO total compensation represents the typical compensation if wealth were distributed equally. However, it's sensitive to extreme values (outliers).\n",
    "\n",
    "**5%-Trimmed Mean**: By removing the top and bottom 5%, this measure provides a robust average less influenced by extreme compensations, better representing the \"typical\" CEO compensation.\n",
    "\n",
    "**Median**: Half of CEOs earn below this value and half above. It's the most representative measure for skewed distributions and shows the compensation of the \"middle\" CEO.\n",
    "\n",
    "**Lower Quartile (Q1)**: 25% of CEOs earn less than this amount, representing the threshold for the lower-paid quarter of executives.\n",
    "\n",
    "**Upper Quartile (Q3)**: 75% of CEOs earn below this value; only the top 25% earn more, indicating the entry point for high-earner CEOs.\n",
    "\n",
    "**5% Quantile**: Only 5% of CEOs earn below this threshold, representing near-minimum compensation levels.\n",
    "\n",
    "**95% Quantile**: Only 5% of CEOs earn above this value, indicating exceptionally high compensation packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1(b) Empirical Cumulative Distribution Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_totcomp = np.sort(totcomp)\n",
    "ecdf_values = np.arange(1, len(sorted_totcomp) + 1) / len(sorted_totcomp)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(sorted_totcomp, ecdf_values, linewidth=2)\n",
    "plt.xlabel('Total Compensation ($1000)', fontsize=12)\n",
    "plt.ylabel('Cumulative Probability', fontsize=12)\n",
    "plt.title('Empirical Cumulative Distribution Function - Total Compensation', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_inv_01 = totcomp.quantile(0.1)\n",
    "f_inv_09 = totcomp.quantile(0.9)\n",
    "\n",
    "f_2000 = (totcomp <= 2000).mean()\n",
    "one_minus_f_4000 = (totcomp > 4000).mean()\n",
    "\n",
    "print(\"ECDF QUANTITIES\\n\" + \"=\"*50)\n",
    "print(f\"F̂⁻¹(0.1): ${f_inv_01:,.2f}\")\n",
    "print(f\"F̂⁻¹(0.9): ${f_inv_09:,.2f}\")\n",
    "print(f\"\\nF̂(2000): {f_2000:.4f} ({f_2000*100:.2f}%)\")\n",
    "print(f\"1 - F̂(4000): {one_minus_f_4000:.4f} ({one_minus_f_4000*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Economic Interpretation:\n",
    "\n",
    "**F̂⁻¹(0.1)**: The 10th percentile shows that 10% of CEOs earn below this compensation level. This represents the lower-income threshold for CEO positions.\n",
    "\n",
    "**F̂⁻¹(0.9)**: The 90th percentile indicates that 90% of CEOs earn less than this amount. CEOs earning above this are in the top 10% of compensations.\n",
    "\n",
    "**F̂(2000)**: The proportion of CEOs earning $2 million or less. This helps understand market concentration at lower compensation levels.\n",
    "\n",
    "**1 - F̂(4000)**: The proportion of CEOs earning more than $4 million, indicating the prevalence of high-compensation packages in the sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1(c) Histogram and Box Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "axes[0].hist(totcomp, bins='auto', edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Total Compensation ($1000)', fontsize=11)\n",
    "axes[0].set_ylabel('Frequency', fontsize=11)\n",
    "axes[0].set_title('Histogram of Total Compensation', fontsize=12)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].boxplot(totcomp, vert=True)\n",
    "axes[1].set_ylabel('Total Compensation ($1000)', fontsize=11)\n",
    "axes[1].set_title('Box Plot of Total Compensation', fontsize=12)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation:\n",
    "\n",
    "**Histogram Area**: Each rectangle's area represents the proportion (or count) of observations within that bin interval. The total area under the histogram sums to the total number of observations (or 1 if normalized).\n",
    "\n",
    "**Box Plot Components**:\n",
    "- Bottom whisker: Minimum or 1.5×IQR below Q1\n",
    "- Box bottom: Q1 (25th percentile)\n",
    "- Line in box: Median (Q2, 50th percentile)\n",
    "- Box top: Q3 (75th percentile)\n",
    "- Top whisker: Maximum or 1.5×IQR above Q3\n",
    "- Points beyond whiskers: Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1(d) Distribution Analysis and Symmetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skewness = totcomp.skew()\n",
    "kurtosis = totcomp.kurtosis()\n",
    "iqr = q3 - q1\n",
    "std_dev = totcomp.std()\n",
    "\n",
    "print(\"DISTRIBUTION CHARACTERISTICS\\n\" + \"=\"*50)\n",
    "print(f\"Skewness: {skewness:.4f}\")\n",
    "print(f\"Kurtosis: {kurtosis:.4f}\")\n",
    "print(f\"IQR: ${iqr:,.2f}\")\n",
    "print(f\"Standard Deviation: ${std_dev:,.2f}\")\n",
    "print(f\"\\nMean vs Median: ${mean_val:,.2f} vs ${median_val:,.2f}\")\n",
    "print(f\"Difference: ${mean_val - median_val:,.2f}\")\n",
    "\n",
    "if skewness > 1:\n",
    "    print(\"\\nThe distribution is HIGHLY RIGHT-SKEWED\")\n",
    "elif skewness > 0.5:\n",
    "    print(\"\\nThe distribution is MODERATELY RIGHT-SKEWED\")\n",
    "else:\n",
    "    print(\"\\nThe distribution is APPROXIMATELY SYMMETRIC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions:\n",
    "\n",
    "The distribution shows strong right skewness, indicating:\n",
    "1. Most CEOs earn relatively moderate compensations\n",
    "2. A small number receive exceptionally high packages (outliers)\n",
    "3. The mean is pulled upward by these extreme values\n",
    "\n",
    "**Appropriateness of Location Measures**:\n",
    "- **Mean**: Less appropriate due to extreme sensitivity to outliers\n",
    "- **Median**: Most appropriate - robust to outliers, better represents typical CEO\n",
    "- **Trimmed mean**: Good compromise between robustness and using all data\n",
    "\n",
    "The high positive skewness suggests we should primarily rely on median and quantiles rather than mean for understanding typical compensation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1(e) Histogram Bandwidth Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Histogram Bandwidth Selection Methods:\\n\" + \"=\"*50)\n",
    "print(\"\\nPython/Matplotlib's 'auto' uses the Sturges' Rule or Freedman-Diaconis method:\")\n",
    "print(\"\\n1. Sturges' Rule: bins = ceil(log2(n) + 1)\")\n",
    "print(\"   Simple but may not work well for non-normal distributions\")\n",
    "print(\"\\n2. Freedman-Diaconis: bin_width = 2 * IQR / n^(1/3)\")\n",
    "print(\"   More robust to outliers, adapts to data spread\")\n",
    "\n",
    "n = len(totcomp)\n",
    "sturges_bins = int(np.ceil(np.log2(n) + 1))\n",
    "fd_bin_width = 2 * iqr / (n ** (1/3))\n",
    "fd_bins = int(np.ceil((totcomp.max() - totcomp.min()) / fd_bin_width))\n",
    "\n",
    "print(f\"\\nFor our data (n={n}):\")\n",
    "print(f\"Sturges suggests: {sturges_bins} bins\")\n",
    "print(f\"Freedman-Diaconis suggests: {fd_bins} bins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "axes[0].hist(totcomp, bins=5, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_title('Too Rough (5 bins)', fontsize=12)\n",
    "axes[0].set_xlabel('Total Compensation ($1000)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].hist(totcomp, bins='auto', edgecolor='black', alpha=0.7)\n",
    "axes[1].set_title('Optimal (auto)', fontsize=12)\n",
    "axes[1].set_xlabel('Total Compensation ($1000)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[2].hist(totcomp, bins=100, edgecolor='black', alpha=0.7)\n",
    "axes[2].set_title('Too Detailed (100 bins)', fontsize=12)\n",
    "axes[2].set_xlabel('Total Compensation ($1000)')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nLearnings:\")\n",
    "print(\"- TOO ROUGH: Loses important distribution features, over-smooths data\")\n",
    "print(\"- OPTIMAL: Balances detail and clarity, reveals true distribution shape\")\n",
    "print(\"- TOO DETAILED: Shows noise, makes interpretation difficult, irregular bars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1(f) Log Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_totcomp = np.log(totcomp)\n",
    "\n",
    "log_mean = log_totcomp.mean()\n",
    "log_median = log_totcomp.median()\n",
    "log_skewness = log_totcomp.skew()\n",
    "\n",
    "print(\"LOG-TRANSFORMED STATISTICS\\n\" + \"=\"*50)\n",
    "print(f\"Original Mean: ${mean_val:,.2f}\")\n",
    "print(f\"Original Median: ${median_val:,.2f}\")\n",
    "print(f\"Original Skewness: {skewness:.4f}\")\n",
    "print(f\"\\nLog Mean: {log_mean:.4f}\")\n",
    "print(f\"Log Median: {log_median:.4f}\")\n",
    "print(f\"Log Skewness: {log_skewness:.4f}\")\n",
    "print(f\"\\nSkewness reduction: {abs(skewness - log_skewness):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "axes[0, 0].hist(totcomp, bins='auto', edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].set_title('Original: Histogram', fontsize=12)\n",
    "axes[0, 0].set_xlabel('Total Compensation ($1000)')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[0, 1].boxplot(totcomp, vert=True)\n",
    "axes[0, 1].set_title('Original: Box Plot', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Total Compensation ($1000)')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 0].hist(log_totcomp, bins='auto', edgecolor='black', alpha=0.7, color='green')\n",
    "axes[1, 0].set_title('Log-Transformed: Histogram', fontsize=12)\n",
    "axes[1, 0].set_xlabel('ln(Total Compensation)')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 1].boxplot(log_totcomp, vert=True)\n",
    "axes[1, 1].set_title('Log-Transformed: Box Plot', fontsize=12)\n",
    "axes[1, 1].set_ylabel('ln(Total Compensation)')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Economic Interpretation of Log Transformation:\n",
    "\n",
    "**Why logarithms work**:\n",
    "- Converts multiplicative relationships to additive ones\n",
    "- Compresses the scale, reducing impact of extreme values\n",
    "- Makes percentage changes interpretable as linear differences\n",
    "\n",
    "**Key findings**:\n",
    "1. The log-transformed distribution is much more symmetric\n",
    "2. Mean and median become closer, indicating better balance\n",
    "3. Outliers are less extreme on the log scale\n",
    "4. The distribution approximates normality better\n",
    "\n",
    "**Economic meaning**:\n",
    "- Original scale: Dollar differences matter (e.g., $1M to $2M)\n",
    "- Log scale: Proportional/percentage differences matter (e.g., doubling compensation)\n",
    "- Log transformation suggests CEO compensation may follow a log-normal distribution, common in income data\n",
    "- This implies that percentage changes in compensation are more consistent than absolute changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2(a) Correlation Analysis - Pearson Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = ['salary', 'totcomp', 'tenure', 'age', 'sales', 'profits', 'assets']\n",
    "df_numeric = df[numeric_cols].dropna()\n",
    "\n",
    "pearson_corr = df_numeric.corr(method='pearson')\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(pearson_corr, annot=True, fmt='.3f', cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Pearson Correlation Heatmap', fontsize=14, pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSTRONGEST CORRELATIONS WITH TOTCOMP:\")\n",
    "print(\"=\"*50)\n",
    "totcomp_corrs = pearson_corr['totcomp'].drop('totcomp').sort_values(ascending=False)\n",
    "for var, corr in totcomp_corrs.items():\n",
    "    strength = \"Very Strong\" if abs(corr) > 0.8 else \"Strong\" if abs(corr) > 0.6 else \"Moderate\" if abs(corr) > 0.4 else \"Weak\"\n",
    "    print(f\"{var:10s}: {corr:6.3f}  ({strength})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion:\n",
    "\n",
    "The Pearson correlation measures linear relationships between variables. Key observations:\n",
    "- **Strong positive correlations** suggest variables move together linearly\n",
    "- **Weak correlations** may indicate non-linear relationships or no relationship\n",
    "- Company size metrics (sales, assets) often correlate with CEO compensation\n",
    "- Personal characteristics (age, tenure) may show different patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2(b) Scatter Plots and Spearman Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_vars = ['salary', 'tenure', 'age', 'sales']\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, var in enumerate(scatter_vars):\n",
    "    axes[idx].scatter(df_numeric[var], df_numeric['totcomp'], alpha=0.5)\n",
    "    axes[idx].set_xlabel(var, fontsize=11)\n",
    "    axes[idx].set_ylabel('totcomp', fontsize=11)\n",
    "    axes[idx].set_title(f'totcomp vs {var}', fontsize=12)\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "    \n",
    "    z = np.polyfit(df_numeric[var], df_numeric['totcomp'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    axes[idx].plot(df_numeric[var], p(df_numeric[var]), \"r--\", alpha=0.8, linewidth=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearman_corr = df_numeric.corr(method='spearman')\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(spearman_corr, annot=True, fmt='.3f', cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Spearman Correlation Heatmap', fontsize=14, pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nCOMPARISON: PEARSON vs SPEARMAN\\n\" + \"=\"*60)\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Variable': totcomp_corrs.index,\n",
    "    'Pearson': totcomp_corrs.values,\n",
    "    'Spearman': spearman_corr['totcomp'].drop('totcomp').loc[totcomp_corrs.index].values\n",
    "})\n",
    "comparison_df['Difference'] = comparison_df['Spearman'] - comparison_df['Pearson']\n",
    "print(comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis:\n",
    "\n",
    "**Appropriateness of Pearson correlation**:\n",
    "- Check scatter plots for linearity\n",
    "- If relationships are non-linear or have outliers, Pearson may not capture true association\n",
    "\n",
    "**Spearman vs Pearson**:\n",
    "- **Spearman** measures monotonic relationships (consistent direction)\n",
    "- **Pearson** measures linear relationships (straight line)\n",
    "- Large differences indicate non-linear but monotonic relationships\n",
    "- Spearman is more robust to outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2(c) Rank Analysis and Correlation Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_value = 6737\n",
    "rank = (df_numeric['totcomp'] <= target_value).sum()\n",
    "percentile = (rank / len(df_numeric)) * 100\n",
    "\n",
    "print(f\"RANK ANALYSIS FOR TOTCOMP = {target_value}\\n\" + \"=\"*50)\n",
    "print(f\"Rank: {rank} out of {len(df_numeric)}\")\n",
    "print(f\"Percentile: {percentile:.2f}%\")\n",
    "print(f\"\\nThis CEO earns more than {rank} other CEOs ({percentile:.1f}% of the sample)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conceptual Difference Between Correlations:\n",
    "\n",
    "**Pearson Correlation**:\n",
    "- Measures **linear dependence**: how well data fits a straight line\n",
    "- Uses actual values of variables\n",
    "- Sensitive to outliers and scale\n",
    "- Appropriate when relationship is linear\n",
    "- Formula based on covariance and standard deviations\n",
    "\n",
    "**Spearman Correlation**:\n",
    "- Measures **monotonic dependence**: consistent increase/decrease direction\n",
    "- Uses ranks (positions) instead of actual values\n",
    "- Robust to outliers and non-linear transformations\n",
    "- Captures any consistent trend, not just linear\n",
    "- Essentially Pearson correlation applied to ranks\n",
    "\n",
    "**Example**:\n",
    "- Linear relationship: y = 2x → Both correlations = 1\n",
    "- Exponential relationship: y = e^x → Spearman = 1, Pearson < 1\n",
    "- U-shaped relationship: y = x² → Both correlations ≈ 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2(d) Age Subgroup Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "younger = df_numeric[df_numeric['age'] < 50]['totcomp']\n",
    "older = df_numeric[df_numeric['age'] >= 50]['totcomp']\n",
    "\n",
    "print(f\"SUBGROUP ANALYSIS\\n\" + \"=\"*60)\n",
    "print(f\"Younger than 50: n = {len(younger)}\")\n",
    "print(f\"50 or older: n = {len(older)}\")\n",
    "\n",
    "print(f\"\\nLOCATION MEASURES:\")\n",
    "print(f\"{'Measure':<20} {'Age < 50':>15} {'Age >= 50':>15}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Mean':<20} ${younger.mean():>14,.2f} ${older.mean():>14,.2f}\")\n",
    "print(f\"{'Median':<20} ${younger.median():>14,.2f} ${older.median():>14,.2f}\")\n",
    "print(f\"{'Q1':<20} ${younger.quantile(0.25):>14,.2f} ${older.quantile(0.25):>14,.2f}\")\n",
    "print(f\"{'Q3':<20} ${younger.quantile(0.75):>14,.2f} ${older.quantile(0.75):>14,.2f}\")\n",
    "\n",
    "print(f\"\\nDISPERSION MEASURES:\")\n",
    "print(f\"{'Measure':<20} {'Age < 50':>15} {'Age >= 50':>15}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Std Dev':<20} ${younger.std():>14,.2f} ${older.std():>14,.2f}\")\n",
    "print(f\"{'IQR':<20} ${(younger.quantile(0.75)-younger.quantile(0.25)):>14,.2f} ${(older.quantile(0.75)-older.quantile(0.25)):>14,.2f}\")\n",
    "print(f\"{'CV':<20} {(younger.std()/younger.mean()):>15.4f} {(older.std()/older.mean()):>15.4f}\")\n",
    "print(f\"{'Range':<20} ${(younger.max()-younger.min()):>14,.2f} ${(older.max()-older.min()):>14,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "axes[0].hist(younger, bins=20, alpha=0.6, label='Age < 50', edgecolor='black')\n",
    "axes[0].hist(older, bins=20, alpha=0.6, label='Age >= 50', edgecolor='black')\n",
    "axes[0].set_xlabel('Total Compensation ($1000)', fontsize=11)\n",
    "axes[0].set_ylabel('Frequency', fontsize=11)\n",
    "axes[0].set_title('Overlapping Histograms by Age Group', fontsize=12)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "sorted_younger = np.sort(younger)\n",
    "sorted_older = np.sort(older)\n",
    "ecdf_younger = np.arange(1, len(sorted_younger) + 1) / len(sorted_younger)\n",
    "ecdf_older = np.arange(1, len(sorted_older) + 1) / len(sorted_older)\n",
    "\n",
    "axes[1].plot(sorted_younger, ecdf_younger, label='Age < 50', linewidth=2)\n",
    "axes[1].plot(sorted_older, ecdf_older, label='Age >= 50', linewidth=2)\n",
    "axes[1].set_xlabel('Total Compensation ($1000)', fontsize=11)\n",
    "axes[1].set_ylabel('Cumulative Probability', fontsize=11)\n",
    "axes[1].set_title('Empirical CDFs by Age Group', fontsize=12)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion:\n",
    "\n",
    "**Location measures** tell us about central tendency:\n",
    "- Do older CEOs earn more on average?\n",
    "- What's the typical compensation in each group?\n",
    "\n",
    "**Dispersion measures** tell us about variability:\n",
    "- **Standard Deviation**: Absolute variability in dollars\n",
    "- **IQR**: Spread of middle 50%, robust to outliers\n",
    "- **Coefficient of Variation**: Relative variability (std/mean), allows comparison across groups\n",
    "- **Range**: Full spread, sensitive to extremes\n",
    "\n",
    "**Key learnings**:\n",
    "- Compare not just averages but also spread\n",
    "- Higher dispersion suggests more inequality within group\n",
    "- ECDFs show entire distribution, revealing differences beyond summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Contingency Table Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df[['salary', 'age']].dropna()\n",
    "\n",
    "df_clean['S'] = pd.cut(df_clean['salary'], \n",
    "                        bins=[-np.inf, 3000, 5000, np.inf],\n",
    "                        labels=['S1', 'S2', 'S3'])\n",
    "\n",
    "df_clean['A'] = pd.cut(df_clean['age'],\n",
    "                       bins=[-np.inf, 50, np.inf],\n",
    "                       labels=['A1', 'A2'])\n",
    "\n",
    "contingency_absolute = pd.crosstab(df_clean['A'], df_clean['S'], margins=True)\n",
    "contingency_relative = pd.crosstab(df_clean['A'], df_clean['S'], normalize=True, margins=True)\n",
    "\n",
    "print(\"CONTINGENCY TABLE - ABSOLUTE FREQUENCIES\\n\" + \"=\"*60)\n",
    "print(contingency_absolute)\n",
    "print(\"\\n\\nCONTINGENCY TABLE - RELATIVE FREQUENCIES\\n\" + \"=\"*60)\n",
    "print(contingency_relative.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3(b) Interpretation of Table Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n12 = contingency_absolute.loc['A1', 'S2']\n",
    "h12 = contingency_relative.loc['A1', 'S2']\n",
    "n1_dot = contingency_absolute.loc['A1', 'All']\n",
    "h1_dot = contingency_relative.loc['A1', 'All']\n",
    "\n",
    "print(\"INTERPRETATION OF TABLE VALUES\\n\" + \"=\"*60)\n",
    "print(f\"\\nn₁₂ = {n12}\")\n",
    "print(f\"Interpretation: {n12} CEOs are younger than 50 AND have salary between $3000-5000K\")\n",
    "\n",
    "print(f\"\\nh₁₂ = {h12:.4f}\")\n",
    "print(f\"Interpretation: {h12*100:.2f}% of all CEOs are younger than 50 AND earn $3000-5000K\")\n",
    "\n",
    "print(f\"\\nn₁• = {n1_dot}\")\n",
    "print(f\"Interpretation: Total number of CEOs younger than 50 (marginal frequency)\")\n",
    "\n",
    "print(f\"\\nh₁• = {h1_dot:.4f}\")\n",
    "print(f\"Interpretation: {h1_dot*100:.2f}% of all CEOs are younger than 50 (marginal proportion)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3(c) Dependence Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_no_margins = pd.crosstab(df_clean['A'], df_clean['S'])\n",
    "\n",
    "chi2, p_value, dof, expected = stats.chi2_contingency(contingency_no_margins)\n",
    "\n",
    "n_total = contingency_no_margins.sum().sum()\n",
    "cramers_v = np.sqrt(chi2 / (n_total * (min(contingency_no_margins.shape) - 1)))\n",
    "\n",
    "print(\"DEPENDENCE ANALYSIS\\n\" + \"=\"*60)\n",
    "print(f\"Chi-square statistic: {chi2:.4f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "print(f\"Degrees of freedom: {dof}\")\n",
    "print(f\"Cramér's V: {cramers_v:.4f}\")\n",
    "\n",
    "print(f\"\\nINTERPRETATION:\")\n",
    "if p_value < 0.05:\n",
    "    print(\"✓ Variables are statistically dependent (p < 0.05)\")\n",
    "else:\n",
    "    print(\"✗ No significant dependence detected (p >= 0.05)\")\n",
    "\n",
    "if cramers_v < 0.1:\n",
    "    strength = \"negligible\"\n",
    "elif cramers_v < 0.3:\n",
    "    strength = \"weak\"\n",
    "elif cramers_v < 0.5:\n",
    "    strength = \"moderate\"\n",
    "else:\n",
    "    strength = \"strong\"\n",
    "\n",
    "print(f\"Cramér's V indicates {strength} association between age and salary groups\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Can We Infer?\n",
    "\n",
    "**About Co-movement**:\n",
    "- Cramér's V measures strength of association (0 = independent, 1 = perfect)\n",
    "- Cannot determine direction (positive/negative) from chi-square test\n",
    "- Shows whether knowing age helps predict salary category\n",
    "\n",
    "**About Opposite Directions**:\n",
    "- Chi-square test does NOT measure direction of relationship\n",
    "- Need to examine conditional probabilities or odds ratios for direction\n",
    "- For nominal variables like these categories, \"opposite direction\" is not well-defined\n",
    "\n",
    "**Better approach for direction**:\n",
    "- Compare P(high salary | older) vs P(high salary | younger)\n",
    "- Examine the standardized residuals from chi-square test\n",
    "- Use conditional probability tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditional_probs = pd.crosstab(df_clean['A'], df_clean['S'], normalize='index')\n",
    "\n",
    "print(\"\\nCONDITIONAL PROBABILITIES (Row Percentages)\\n\" + \"=\"*60)\n",
    "print(\"P(Salary Category | Age Group):\\n\")\n",
    "print(conditional_probs.round(4))\n",
    "\n",
    "print(\"\\nINTERPRETATION:\")\n",
    "print(\"Each row shows the distribution of salary categories within that age group.\")\n",
    "print(\"This helps us understand: Do older CEOs have different salary distributions?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Conclusions\n",
    "\n",
    "This analysis revealed several key insights about CEO compensation:\n",
    "\n",
    "1. **Distribution**: Highly right-skewed with significant outliers\n",
    "2. **Central Tendency**: Median more appropriate than mean due to skewness\n",
    "3. **Transformation**: Log transformation normalizes distribution\n",
    "4. **Correlations**: Company size metrics strongly correlate with compensation\n",
    "5. **Age Effects**: Differences exist between age groups in both location and spread\n",
    "6. **Categorical Relationships**: Salary and age categories show measurable association"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
